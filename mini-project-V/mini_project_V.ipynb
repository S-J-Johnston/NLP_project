{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identifying Duplicate Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Over 100 million people visit Quora every month, so it's no surprise that many people ask similar (or the same) questions. Various questions with the same intent can cause people to spend extra time searching for the best answer to their question, and results in members answering multiple versions of the same question. Quora uses random forest to identify duplicated questions to provide a better experience to active seekers and writers, and offer more value to both of these groups in the long term.\n",
    "Follow the steps outlined below to build the appropriate classifier model. \n",
    "\n",
    "\n",
    "Steps:\n",
    "- Download data\n",
    "- Exploration\n",
    "- Cleaning\n",
    "- Feature Engineering\n",
    "- Modeling\n",
    "\n",
    "By the end of this project you should have **a presentation that describes the model you built** and its **performance**. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8067</th>\n",
       "      <td>8067</td>\n",
       "      <td>15738</td>\n",
       "      <td>15739</td>\n",
       "      <td>How do I play Pokémon GO in Korea?</td>\n",
       "      <td>How do I play Pokémon GO in China?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368101</th>\n",
       "      <td>368101</td>\n",
       "      <td>12736</td>\n",
       "      <td>104117</td>\n",
       "      <td>What are some of the best side dishes for crab...</td>\n",
       "      <td>What are some good side dishes for buffalo chi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70497</th>\n",
       "      <td>70497</td>\n",
       "      <td>121486</td>\n",
       "      <td>121487</td>\n",
       "      <td>Which is more advisable and better material fo...</td>\n",
       "      <td>What is the best server setup for buddypress?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226567</th>\n",
       "      <td>226567</td>\n",
       "      <td>254474</td>\n",
       "      <td>258192</td>\n",
       "      <td>How do I improve logical programming skills?</td>\n",
       "      <td>How can I improve my logical skills for progra...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73186</th>\n",
       "      <td>73186</td>\n",
       "      <td>48103</td>\n",
       "      <td>3062</td>\n",
       "      <td>How close we are to see 3rd world war?</td>\n",
       "      <td>How close is a World War III?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id    qid1    qid2  \\\n",
       "8067      8067   15738   15739   \n",
       "368101  368101   12736  104117   \n",
       "70497    70497  121486  121487   \n",
       "226567  226567  254474  258192   \n",
       "73186    73186   48103    3062   \n",
       "\n",
       "                                                question1  \\\n",
       "8067                   How do I play Pokémon GO in Korea?   \n",
       "368101  What are some of the best side dishes for crab...   \n",
       "70497   Which is more advisable and better material fo...   \n",
       "226567       How do I improve logical programming skills?   \n",
       "73186              How close we are to see 3rd world war?   \n",
       "\n",
       "                                                question2  is_duplicate  \n",
       "8067                   How do I play Pokémon GO in China?             0  \n",
       "368101  What are some good side dishes for buffalo chi...             0  \n",
       "70497       What is the best server setup for buddypress?             0  \n",
       "226567  How can I improve my logical skills for progra...             1  \n",
       "73186                       How close is a World War III?             1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample = df.sample(frac = 0.1, random_state = 42)\n",
    "df_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40429, 6)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note\n",
    "There is no designated test.csv file. The train.csv file is the entire dataset. Part of the data in the train.csv file should be set aside to act as the final testing data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 40429 entries, 8067 to 291758\n",
      "Data columns (total 6 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   id            40429 non-null  int64 \n",
      " 1   qid1          40429 non-null  int64 \n",
      " 2   qid2          40429 non-null  int64 \n",
      " 3   question1     40429 non-null  object\n",
      " 4   question2     40429 non-null  object\n",
      " 5   is_duplicate  40429 non-null  int64 \n",
      "dtypes: int64(4), object(2)\n",
      "memory usage: 2.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df_sample.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    25497\n",
       "1    14932\n",
       "Name: is_duplicate, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample['is_duplicate'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nulls in label: 0\n",
      "Number of nulls in q1: 0\n",
      "Number of nulls in q2: 0\n"
     ]
    }
   ],
   "source": [
    "# Are we missing any data?\n",
    "print('Number of nulls in label: {}'.format(df_sample['is_duplicate'].isnull().sum()))\n",
    "print('Number of nulls in q1: {}'.format(df_sample['question1'].isnull().sum()))\n",
    "print('Number of nulls in q2: {}'.format(df_sample['question2'].isnull().sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning\n",
    "\n",
    "- Tokenization\n",
    "- Stopwords cleaning\n",
    "- Removing punctuation\n",
    "- Normalizing\n",
    "- Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns\n",
    "df_sample = df_sample[['question1', 'question2', 'is_duplicate']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample['question_merged'] = df_sample['question1'] + ' ' + df_sample['question2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>question_merged</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8067</th>\n",
       "      <td>How do I play Pokémon GO in Korea?</td>\n",
       "      <td>How do I play Pokémon GO in China?</td>\n",
       "      <td>0</td>\n",
       "      <td>How do I play Pokémon GO in Korea? How do I pl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368101</th>\n",
       "      <td>What are some of the best side dishes for crab...</td>\n",
       "      <td>What are some good side dishes for buffalo chi...</td>\n",
       "      <td>0</td>\n",
       "      <td>What are some of the best side dishes for crab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70497</th>\n",
       "      <td>Which is more advisable and better material fo...</td>\n",
       "      <td>What is the best server setup for buddypress?</td>\n",
       "      <td>0</td>\n",
       "      <td>Which is more advisable and better material fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226567</th>\n",
       "      <td>How do I improve logical programming skills?</td>\n",
       "      <td>How can I improve my logical skills for progra...</td>\n",
       "      <td>1</td>\n",
       "      <td>How do I improve logical programming skills? H...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73186</th>\n",
       "      <td>How close we are to see 3rd world war?</td>\n",
       "      <td>How close is a World War III?</td>\n",
       "      <td>1</td>\n",
       "      <td>How close we are to see 3rd world war? How clo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                question1  \\\n",
       "8067                   How do I play Pokémon GO in Korea?   \n",
       "368101  What are some of the best side dishes for crab...   \n",
       "70497   Which is more advisable and better material fo...   \n",
       "226567       How do I improve logical programming skills?   \n",
       "73186              How close we are to see 3rd world war?   \n",
       "\n",
       "                                                question2  is_duplicate  \\\n",
       "8067                   How do I play Pokémon GO in China?             0   \n",
       "368101  What are some good side dishes for buffalo chi...             0   \n",
       "70497       What is the best server setup for buddypress?             0   \n",
       "226567  How can I improve my logical skills for progra...             1   \n",
       "73186                       How close is a World War III?             1   \n",
       "\n",
       "                                          question_merged  \n",
       "8067    How do I play Pokémon GO in Korea? How do I pl...  \n",
       "368101  What are some of the best side dishes for crab...  \n",
       "70497   Which is more advisable and better material fo...  \n",
       "226567  How do I improve logical programming skills? H...  \n",
       "73186   How close we are to see 3rd world war? How clo...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 40429 entries, 8067 to 291758\n",
      "Data columns (total 4 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   question1        40429 non-null  object\n",
      " 1   question2        40429 non-null  object\n",
      " 2   is_duplicate     40429 non-null  int64 \n",
      " 3   question_merged  40429 non-null  object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 1.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df_sample.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove punctuation\n",
    "import string\n",
    "\n",
    "def remove_punct(text):\n",
    "    text = \"\".join([char for char in text if char not in string.punctuation])\n",
    "    return text\n",
    "\n",
    "df_sample['question_merged'] = df_sample['question_merged'].apply(lambda x: remove_punct(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the NLTK package and download the necessary data\n",
    "import nltk\n",
    "#nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "ENGstopwords = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stopword, tokenize and tf-idf\n",
    "input_ = df_sample['question_merged']\n",
    "vectorizer = TfidfVectorizer(strip_accents = 'ascii', lowercase = True, stop_words = 'english')\n",
    "X = vectorizer.fit_transform(input_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40429, 33268)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Words to Vec Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize\n",
    "import re\n",
    "\n",
    "def tokenize(text):\n",
    "    tokens = text.split()\n",
    "    return tokens\n",
    "\n",
    "df_sample['q12_token'] = df_sample['question_merged'].apply(lambda x: tokenize(x.lower()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>question_merged</th>\n",
       "      <th>q12_token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8067</th>\n",
       "      <td>How do I play Pokémon GO in Korea?</td>\n",
       "      <td>How do I play Pokémon GO in China?</td>\n",
       "      <td>0</td>\n",
       "      <td>How do I play Pokémon GO in Korea How do I pla...</td>\n",
       "      <td>[how, do, i, play, pokémon, go, in, korea, how...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368101</th>\n",
       "      <td>What are some of the best side dishes for crab...</td>\n",
       "      <td>What are some good side dishes for buffalo chi...</td>\n",
       "      <td>0</td>\n",
       "      <td>What are some of the best side dishes for crab...</td>\n",
       "      <td>[what, are, some, of, the, best, side, dishes,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70497</th>\n",
       "      <td>Which is more advisable and better material fo...</td>\n",
       "      <td>What is the best server setup for buddypress?</td>\n",
       "      <td>0</td>\n",
       "      <td>Which is more advisable and better material fo...</td>\n",
       "      <td>[which, is, more, advisable, and, better, mate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226567</th>\n",
       "      <td>How do I improve logical programming skills?</td>\n",
       "      <td>How can I improve my logical skills for progra...</td>\n",
       "      <td>1</td>\n",
       "      <td>How do I improve logical programming skills Ho...</td>\n",
       "      <td>[how, do, i, improve, logical, programming, sk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73186</th>\n",
       "      <td>How close we are to see 3rd world war?</td>\n",
       "      <td>How close is a World War III?</td>\n",
       "      <td>1</td>\n",
       "      <td>How close we are to see 3rd world war How clos...</td>\n",
       "      <td>[how, close, we, are, to, see, 3rd, world, war...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                question1  \\\n",
       "8067                   How do I play Pokémon GO in Korea?   \n",
       "368101  What are some of the best side dishes for crab...   \n",
       "70497   Which is more advisable and better material fo...   \n",
       "226567       How do I improve logical programming skills?   \n",
       "73186              How close we are to see 3rd world war?   \n",
       "\n",
       "                                                question2  is_duplicate  \\\n",
       "8067                   How do I play Pokémon GO in China?             0   \n",
       "368101  What are some good side dishes for buffalo chi...             0   \n",
       "70497       What is the best server setup for buddypress?             0   \n",
       "226567  How can I improve my logical skills for progra...             1   \n",
       "73186                       How close is a World War III?             1   \n",
       "\n",
       "                                          question_merged  \\\n",
       "8067    How do I play Pokémon GO in Korea How do I pla...   \n",
       "368101  What are some of the best side dishes for crab...   \n",
       "70497   Which is more advisable and better material fo...   \n",
       "226567  How do I improve logical programming skills Ho...   \n",
       "73186   How close we are to see 3rd world war How clos...   \n",
       "\n",
       "                                                q12_token  \n",
       "8067    [how, do, i, play, pokémon, go, in, korea, how...  \n",
       "368101  [what, are, some, of, the, best, side, dishes,...  \n",
       "70497   [which, is, more, advisable, and, better, mate...  \n",
       "226567  [how, do, i, improve, logical, programming, sk...  \n",
       "73186   [how, close, we, are, to, see, 3rd, world, war...  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop stopwords\n",
    "def remove_stopwords(tokenized_text):    \n",
    "    text = [word for word in tokenized_text if word not in ENGstopwords]\n",
    "    return text\n",
    "\n",
    "df_sample['q12_token_stop'] = df_sample['q12_token'].apply(lambda x: remove_stopwords(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>question_merged</th>\n",
       "      <th>q12_token</th>\n",
       "      <th>q12_token_stop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8067</th>\n",
       "      <td>How do I play Pokémon GO in Korea?</td>\n",
       "      <td>How do I play Pokémon GO in China?</td>\n",
       "      <td>0</td>\n",
       "      <td>How do I play Pokémon GO in Korea How do I pla...</td>\n",
       "      <td>[how, do, i, play, pokémon, go, in, korea, how...</td>\n",
       "      <td>[play, pokémon, go, korea, play, pokémon, go, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368101</th>\n",
       "      <td>What are some of the best side dishes for crab...</td>\n",
       "      <td>What are some good side dishes for buffalo chi...</td>\n",
       "      <td>0</td>\n",
       "      <td>What are some of the best side dishes for crab...</td>\n",
       "      <td>[what, are, some, of, the, best, side, dishes,...</td>\n",
       "      <td>[best, side, dishes, crab, cakes, good, side, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70497</th>\n",
       "      <td>Which is more advisable and better material fo...</td>\n",
       "      <td>What is the best server setup for buddypress?</td>\n",
       "      <td>0</td>\n",
       "      <td>Which is more advisable and better material fo...</td>\n",
       "      <td>[which, is, more, advisable, and, better, mate...</td>\n",
       "      <td>[advisable, better, material, crash, test, aut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226567</th>\n",
       "      <td>How do I improve logical programming skills?</td>\n",
       "      <td>How can I improve my logical skills for progra...</td>\n",
       "      <td>1</td>\n",
       "      <td>How do I improve logical programming skills Ho...</td>\n",
       "      <td>[how, do, i, improve, logical, programming, sk...</td>\n",
       "      <td>[improve, logical, programming, skills, improv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73186</th>\n",
       "      <td>How close we are to see 3rd world war?</td>\n",
       "      <td>How close is a World War III?</td>\n",
       "      <td>1</td>\n",
       "      <td>How close we are to see 3rd world war How clos...</td>\n",
       "      <td>[how, close, we, are, to, see, 3rd, world, war...</td>\n",
       "      <td>[close, see, 3rd, world, war, close, world, wa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                question1  \\\n",
       "8067                   How do I play Pokémon GO in Korea?   \n",
       "368101  What are some of the best side dishes for crab...   \n",
       "70497   Which is more advisable and better material fo...   \n",
       "226567       How do I improve logical programming skills?   \n",
       "73186              How close we are to see 3rd world war?   \n",
       "\n",
       "                                                question2  is_duplicate  \\\n",
       "8067                   How do I play Pokémon GO in China?             0   \n",
       "368101  What are some good side dishes for buffalo chi...             0   \n",
       "70497       What is the best server setup for buddypress?             0   \n",
       "226567  How can I improve my logical skills for progra...             1   \n",
       "73186                       How close is a World War III?             1   \n",
       "\n",
       "                                          question_merged  \\\n",
       "8067    How do I play Pokémon GO in Korea How do I pla...   \n",
       "368101  What are some of the best side dishes for crab...   \n",
       "70497   Which is more advisable and better material fo...   \n",
       "226567  How do I improve logical programming skills Ho...   \n",
       "73186   How close we are to see 3rd world war How clos...   \n",
       "\n",
       "                                                q12_token  \\\n",
       "8067    [how, do, i, play, pokémon, go, in, korea, how...   \n",
       "368101  [what, are, some, of, the, best, side, dishes,...   \n",
       "70497   [which, is, more, advisable, and, better, mate...   \n",
       "226567  [how, do, i, improve, logical, programming, sk...   \n",
       "73186   [how, close, we, are, to, see, 3rd, world, war...   \n",
       "\n",
       "                                           q12_token_stop  \n",
       "8067    [play, pokémon, go, korea, play, pokémon, go, ...  \n",
       "368101  [best, side, dishes, crab, cakes, good, side, ...  \n",
       "70497   [advisable, better, material, crash, test, aut...  \n",
       "226567  [improve, logical, programming, skills, improv...  \n",
       "73186   [close, see, 3rd, world, war, close, world, wa...  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemming(array):\n",
    "    return [stemmer.stem(token) for token in array]\n",
    "\n",
    "df_sample['stemmed'] = df_sample['q12_token_stop'].apply(stemming)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>question_merged</th>\n",
       "      <th>q12_token</th>\n",
       "      <th>q12_token_stop</th>\n",
       "      <th>stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8067</th>\n",
       "      <td>How do I play Pokémon GO in Korea?</td>\n",
       "      <td>How do I play Pokémon GO in China?</td>\n",
       "      <td>0</td>\n",
       "      <td>How do I play Pokémon GO in Korea How do I pla...</td>\n",
       "      <td>[how, do, i, play, pokémon, go, in, korea, how...</td>\n",
       "      <td>[play, pokémon, go, korea, play, pokémon, go, ...</td>\n",
       "      <td>[play, pokémon, go, korea, play, pokémon, go, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368101</th>\n",
       "      <td>What are some of the best side dishes for crab...</td>\n",
       "      <td>What are some good side dishes for buffalo chi...</td>\n",
       "      <td>0</td>\n",
       "      <td>What are some of the best side dishes for crab...</td>\n",
       "      <td>[what, are, some, of, the, best, side, dishes,...</td>\n",
       "      <td>[best, side, dishes, crab, cakes, good, side, ...</td>\n",
       "      <td>[best, side, dish, crab, cake, good, side, dis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70497</th>\n",
       "      <td>Which is more advisable and better material fo...</td>\n",
       "      <td>What is the best server setup for buddypress?</td>\n",
       "      <td>0</td>\n",
       "      <td>Which is more advisable and better material fo...</td>\n",
       "      <td>[which, is, more, advisable, and, better, mate...</td>\n",
       "      <td>[advisable, better, material, crash, test, aut...</td>\n",
       "      <td>[advis, better, materi, crash, test, automobil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226567</th>\n",
       "      <td>How do I improve logical programming skills?</td>\n",
       "      <td>How can I improve my logical skills for progra...</td>\n",
       "      <td>1</td>\n",
       "      <td>How do I improve logical programming skills Ho...</td>\n",
       "      <td>[how, do, i, improve, logical, programming, sk...</td>\n",
       "      <td>[improve, logical, programming, skills, improv...</td>\n",
       "      <td>[improv, logic, program, skill, improv, logic,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73186</th>\n",
       "      <td>How close we are to see 3rd world war?</td>\n",
       "      <td>How close is a World War III?</td>\n",
       "      <td>1</td>\n",
       "      <td>How close we are to see 3rd world war How clos...</td>\n",
       "      <td>[how, close, we, are, to, see, 3rd, world, war...</td>\n",
       "      <td>[close, see, 3rd, world, war, close, world, wa...</td>\n",
       "      <td>[close, see, 3rd, world, war, close, world, wa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                question1  \\\n",
       "8067                   How do I play Pokémon GO in Korea?   \n",
       "368101  What are some of the best side dishes for crab...   \n",
       "70497   Which is more advisable and better material fo...   \n",
       "226567       How do I improve logical programming skills?   \n",
       "73186              How close we are to see 3rd world war?   \n",
       "\n",
       "                                                question2  is_duplicate  \\\n",
       "8067                   How do I play Pokémon GO in China?             0   \n",
       "368101  What are some good side dishes for buffalo chi...             0   \n",
       "70497       What is the best server setup for buddypress?             0   \n",
       "226567  How can I improve my logical skills for progra...             1   \n",
       "73186                       How close is a World War III?             1   \n",
       "\n",
       "                                          question_merged  \\\n",
       "8067    How do I play Pokémon GO in Korea How do I pla...   \n",
       "368101  What are some of the best side dishes for crab...   \n",
       "70497   Which is more advisable and better material fo...   \n",
       "226567  How do I improve logical programming skills Ho...   \n",
       "73186   How close we are to see 3rd world war How clos...   \n",
       "\n",
       "                                                q12_token  \\\n",
       "8067    [how, do, i, play, pokémon, go, in, korea, how...   \n",
       "368101  [what, are, some, of, the, best, side, dishes,...   \n",
       "70497   [which, is, more, advisable, and, better, mate...   \n",
       "226567  [how, do, i, improve, logical, programming, sk...   \n",
       "73186   [how, close, we, are, to, see, 3rd, world, war...   \n",
       "\n",
       "                                           q12_token_stop  \\\n",
       "8067    [play, pokémon, go, korea, play, pokémon, go, ...   \n",
       "368101  [best, side, dishes, crab, cakes, good, side, ...   \n",
       "70497   [advisable, better, material, crash, test, aut...   \n",
       "226567  [improve, logical, programming, skills, improv...   \n",
       "73186   [close, see, 3rd, world, war, close, world, wa...   \n",
       "\n",
       "                                                  stemmed  \n",
       "8067    [play, pokémon, go, korea, play, pokémon, go, ...  \n",
       "368101  [best, side, dish, crab, cake, good, side, dis...  \n",
       "70497   [advis, better, materi, crash, test, automobil...  \n",
       "226567  [improv, logic, program, skill, improv, logic,...  \n",
       "73186   [close, see, 3rd, world, war, close, world, wa...  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering\n",
    "\n",
    "- tf-idf\n",
    "- word2vec\n",
    "- word count\n",
    "- number of the same words in both questions\n",
    "- ...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questions:\n",
    "    - should the 2 questions columsn be merged so that when we do tf-idf we can see a count of the duplicate words within the list and the words that are not duplicates?\n",
    "    - for words to vec, once it is set up do i just pass that into another model to see if it will work?\n",
    "    - does this need to be completed as a neural network?\n",
    "    - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge question columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#word2vec\n",
    "import gensim\n",
    "\n",
    "Model_SG = gensim.models.Word2Vec(df_sample['q12_token_stop'], vector_size = 100, window = 3, min_count = 2, sg = 1)\n",
    "#Model_SG_stemmed = gensim.models.Word2Vec(df_sample['stemmed'], vector_size = 100, window = 3, min_count = 2, sg = 1)\n",
    "#Model_CBoW = gensim.models.Word2Vec(df_sample['q12_token_stop'], vector_size = 100, window = 5, min_count = 1)\n",
    "#Model_CBoW = gensim.models.Word2Vec(df_sample['stemmed'], vector_size = 100, window = 5, min_count = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what I want to do is calculate the cosine similarity for the 2 sentences based on the w2v model.\n",
    "# the generated models above will be shite so need to load back in the google news model and use that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Key 'how' not present\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [64]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mModel_SG\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msimilarity\u001b[49m\u001b[43m(\u001b[49m\u001b[43ml1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ml2\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/gensim/models/keyedvectors.py:1154\u001b[0m, in \u001b[0;36mKeyedVectors.similarity\u001b[0;34m(self, w1, w2)\u001b[0m\n\u001b[1;32m   1138\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msimilarity\u001b[39m(\u001b[38;5;28mself\u001b[39m, w1, w2):\n\u001b[1;32m   1139\u001b[0m     \u001b[38;5;124;03m\"\"\"Compute cosine similarity between two keys.\u001b[39;00m\n\u001b[1;32m   1140\u001b[0m \n\u001b[1;32m   1141\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1152\u001b[0m \n\u001b[1;32m   1153\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1154\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m dot(matutils\u001b[38;5;241m.\u001b[39munitvec(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mw1\u001b[49m\u001b[43m]\u001b[49m), matutils\u001b[38;5;241m.\u001b[39munitvec(\u001b[38;5;28mself\u001b[39m[w2]))\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/gensim/models/keyedvectors.py:397\u001b[0m, in \u001b[0;36mKeyedVectors.__getitem__\u001b[0;34m(self, key_or_keys)\u001b[0m\n\u001b[1;32m    394\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key_or_keys, _KEY_TYPES):\n\u001b[1;32m    395\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_vector(key_or_keys)\n\u001b[0;32m--> 397\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m vstack([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_vector(key) \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m key_or_keys])\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/gensim/models/keyedvectors.py:397\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    394\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key_or_keys, _KEY_TYPES):\n\u001b[1;32m    395\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_vector(key_or_keys)\n\u001b[0;32m--> 397\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m vstack([\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_vector\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m key_or_keys])\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/gensim/models/keyedvectors.py:438\u001b[0m, in \u001b[0;36mKeyedVectors.get_vector\u001b[0;34m(self, key, norm)\u001b[0m\n\u001b[1;32m    414\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_vector\u001b[39m(\u001b[38;5;28mself\u001b[39m, key, norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    415\u001b[0m     \u001b[38;5;124;03m\"\"\"Get the key's vector, as a 1D numpy array.\u001b[39;00m\n\u001b[1;32m    416\u001b[0m \n\u001b[1;32m    417\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    436\u001b[0m \n\u001b[1;32m    437\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 438\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    439\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m norm:\n\u001b[1;32m    440\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfill_norms()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/gensim/models/keyedvectors.py:412\u001b[0m, in \u001b[0;36mKeyedVectors.get_index\u001b[0;34m(self, key, default)\u001b[0m\n\u001b[1;32m    410\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m default\n\u001b[1;32m    411\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 412\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKey \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m not present\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"Key 'how' not present\""
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling\n",
    "\n",
    "Different modeling techniques can be used:\n",
    "\n",
    "- logistic regression\n",
    "- XGBoost\n",
    "- LSTMs\n",
    "- etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_sample['is_duplicate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize different Classification Models\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import *\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 0.6292673925078428\n",
      "Accuracy score: 0.7515458817709622\n",
      "Confusion matrix:\n",
      " [[4372  784]\n",
      " [1225 1705]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, confusion_matrix, accuracy_score\n",
    "\n",
    "cl1 = RandomForestClassifier(random_state=42)\n",
    "cl1.fit(X_train,y_train)\n",
    "z = cl1.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, z)\n",
    "f1 = f1_score(y_test,z)\n",
    "C = confusion_matrix(y_test,z)\n",
    "print(f'F1 score: {f1}')\n",
    "print(f'Accuracy score: {accuracy}')\n",
    "print(f'Confusion matrix:\\n {C}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 0.5887045979424732\n",
      "Accuracy score: 0.7577294088548108\n",
      "Confusion matrix:\n",
      " [[4725  431]\n",
      " [1528 1402]]\n"
     ]
    }
   ],
   "source": [
    "cl2 = SVC(probability=True, random_state=42)\n",
    "cl2.fit(X_train,y_train)\n",
    "z = cl2.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, z)\n",
    "f1 = f1_score(y_test,z)\n",
    "C = confusion_matrix(y_test,z)\n",
    "print(f'F1 score: {f1}')\n",
    "print(f'Accuracy score: {accuracy}')\n",
    "print(f'Confusion matrix:\\n {C}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 0.561709188964945\n",
      "Accuracy score: 0.738684145436557\n",
      "Confusion matrix:\n",
      " [[4619  537]\n",
      " [1576 1354]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/simonj/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "cl3 = LogisticRegression(random_state=42)\n",
    "cl3.fit(X_train,y_train)\n",
    "z = cl3.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, z)\n",
    "f1 = f1_score(y_test,z)\n",
    "C = confusion_matrix(y_test,z)\n",
    "print(f'F1 score: {f1}')\n",
    "print(f'Accuracy score: {accuracy}')\n",
    "print(f'Confusion matrix:\\n {C}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 0.35945663531870425\n",
      "Accuracy score: 0.6967598318080633\n",
      "Confusion matrix:\n",
      " [[4946  210]\n",
      " [2242  688]]\n"
     ]
    }
   ],
   "source": [
    "cl4 = GradientBoostingClassifier(random_state=42)\n",
    "cl4.fit(X_train,y_train)\n",
    "z = cl4.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, z)\n",
    "f1 = f1_score(y_test,z)\n",
    "C = confusion_matrix(y_test,z)\n",
    "print(f'F1 score: {f1}')\n",
    "print(f'Accuracy score: {accuracy}')\n",
    "print(f'Confusion matrix:\\n {C}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cl1 = RandomForestClassifier(random_state=42)\n",
    "cl2 = SVC(probability=True, random_state=42)\n",
    "cl3 = KNeighborsClassifier()\n",
    "cl4 = LogisticRegression(random_state=42)\n",
    "cl5 = GradientBoostingClassifier(random_state=42)\n",
    "ft1 = PCA()\n",
    "ft2 = SelectKBest()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initiaze the hyperparameters for each dictionary\n",
    "\n",
    "param1 = {}\n",
    "#param1['classifier__n_estimators'] = [2, 5, 10, 15, 50]\n",
    "#param1['classifier__max_depth'] = [5, 10, 20]\n",
    "param1['classifier'] = [cl1]\n",
    "\n",
    "param2 = {}\n",
    "param2['classifier__C'] = [10**-2, 10**-1, 10**0, 10**1, 10**2]\n",
    "#param2['classifier__kernal'] = ['rbf', 'linear']\n",
    "param2['classifier'] = [cl2]\n",
    "\n",
    "param3 = {}\n",
    "#param3['classifier__n_neighbors'] = [2,5,10,25,50]\n",
    "param3['classifier'] = [cl3]\n",
    "\n",
    "param4 = {}\n",
    "param4['classifier__C'] = [10**-2, 10**-1, 10**0, 10**1, 10**2]\n",
    "param4['classifier__penalty'] = ['l1', 'l2']\n",
    "param4['classifier__class_weight'] = [None, {0:1,1:5}, {0:1,1:10}, {0:1,1:25}]\n",
    "param4['classifier__max_iter'] = [250]\n",
    "param4['classifier'] = [cl4]\n",
    "\n",
    "param5 = {}\n",
    "#param5['classifier__n_estimators'] = [2, 5, 10, 50, 100, 250]\n",
    "#param5['classifier__max_depth'] = [5, 10, 20]\n",
    "param5['classifier'] = [cl5]\n",
    "\n",
    "param6 = {}\n",
    "param6['features__pca__n_components'] = [2, 5, 8, 11, 14, 17]\n",
    "param6['features'] = [ft1]\n",
    "\n",
    "param7 = {}\n",
    "param7['features__select_best__k'] = [1, 3, 6]\n",
    "param7['features'] = [ft2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#no feature union\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "\n",
    "classifiers = [cl1, cl2, cl3]\n",
    "\n",
    "#params = [param1, param2, param3, param5]\n",
    "params = [param1, param2, param3, param5]\n",
    "\n",
    "#feature_union = FeatureUnion([('pca', PCA()),\n",
    "                              #('select_best', SelectKBest())])\n",
    "\n",
    "pipeline = Pipeline(steps = [('classifier', 'passthrough')])\n",
    "\n",
    "grid = GridSearchCV(pipeline, param_grid = params, cv=5, scoring='accuracy')\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "best_model = grid.best_estimator_\n",
    "best_hyperparams = grid.best_params_\n",
    "best_acc = grid.score(X_test, y_test)\n",
    "print(f'Best test set accuracy:\\n\\t {best_acc}\\nAchieved with hyperparameters:\\n\\t {best_hyperparams}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set pipeline for for multiple classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine if this needs to be run as an NN..... hopefully not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
